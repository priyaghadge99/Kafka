# Kafka
---------------------
## Prerequisite
https://www.youtube.com/watch?v=ZJJHm_bd9Zo&feature=youtu.be	

Github:
https://gist.github.com/piyushgarg-dev/32cadf6420c452b66a9a6d977ade0b01 
Tool require to run :
1.Nodejs
2.Docker
3.Vscode
for reference code
https://www.sohamkamani.com/nodejs/working-with-kafka/

Note : Run below command in gitbash 

+ Start Zookeper Container and expose PORT 2181.
> docker run -p 2181:2181 zookeeper

+ Start Kafka Container, expose PORT 9092 and setup ENV variables.
> docker run -p 9092:9092 \
> -e KAFKA_ZOOKEEPER_CONNECT=<PRIVATE_IP>:2181 \
> -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://<PRIVATE_IP>:9092 \
> -e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 \
> confluentinc/cp-kafka

or 
Download Kafka from https://kafka.apache.org/downloads	
> tar -xzf kafka_2.10-0.8.2.0.tgz
> cd kafka_2.10-0.8.2.0
Step 2: Start the server

 start zookeeper
> bin/zookeeper-server-start.sh config/zookeeper.properties

Now start the Kafka server:
> bin/kafka-server-start.sh config/server.properties


## Kafka Notes :
https://svn.apache.org/repos/asf/kafka/site/082/quickstart.html

Nodejs Kafka Consumer and producer 
https://gist.github.com/piyushgarg-dev/32cadf6420c452b66a9a6d977ade0b01

## To Run a Consumer/producer
> node producer.js
> node consumer.js


-------Multibroker -Pattern----------------------------------

We can have multiple brokers running as well
> bin/kafka-server-start.sh config/server_0.properties
> bin/kafka-server-start.sh config/server_1.properties
> bin/kafka-server-start.sh config/server_2.properties


As a distributed cluster, Kafka brokers ensure high availability to process records.
Topic has *replication factor* to support not loosing data in case of broker failure. 
You need at least 3 brokers to ensure availability and a replication factor set to 3 for each topic, so no data should be lost.

https://www.learnbestcoding.com/post/123/how-to-create-multiple-brokers-in-apache-kafka


-------------
##Real time use case:
https://medium.com/javarevisited/kafka-with-use-cases-and-real-time-examples-c1e35a0dd07c
LinkedIn: LinkedIn uses Kafka to process and stream real-time user activity data. The platform generates more than 2 trillion messages per day and Kafka helps to manage this massive amount of data by allowing real-time processing and analysis.
Uber: Uber uses Kafka to manage its real-time data streams. Kafka helps Uber to manage the flow of data generated by the companyâ€™s driver and rider applications, including real-time location data, trip data, and payment data.
